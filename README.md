# ğŸ§¬ From Images to Insights: Cell Counting and Uniformity Grading of Day 3 Embryos

This repository contains the official implementation of our paper:

> **From Images to Insights: Cell Counting and Uniformity Grading of Day 3 Embryos**
> Nguyen Duy Tan, Tran Phuong Huy, Tran Thi Thanh Thuy, Hoang Thi Diem Tuyet, Dang Truong Son, Pham The Bao, Vu Ngoc Thanh Sang

---

## ğŸ“Œ Overview

This project presents a robust and automated pipeline for evaluating **Day 3 embryos** by performing **blastomere detection**, **boundary refinement**, and **uniformity assessment**.
Our hybrid approach integrates:

* **YOLOv8-based object detection**
* **GVF-based active contour refinement**
* A novel **Normalized Uniformity Value (NUV)** for grading consistency

The architecture follows the **Chain of Responsibility** and **Builder** design patterns for clean modularity and extensibility.

---

## ğŸ“ Project Structure

```
Embryo_Insights/
â”œâ”€â”€ main.py                         # Entry point for executing the full pipeline
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ LICENSE                         # License information
â”œâ”€â”€ README.md                       # You are here
â”‚
â”œâ”€â”€ abstract/                       # Abstract base classes for all processes
â”œâ”€â”€ adapter/                        # YOLOv8 ONNX adapter and inference tools
â”œâ”€â”€ algorithms/                     # Core implementations (enhancement, detection, contours, grading)
â”œâ”€â”€ config/                         # Pipeline configuration files (YAML)
â”œâ”€â”€ manager/                        # Chain-of-responsibility handler
â”œâ”€â”€ registry/                       # Registry and builder for pipeline creation
â”œâ”€â”€ data/                           # Sample microscope and timelapse embryo images
â”œâ”€â”€ scripts/                        # Scripts for batch evaluation
â””â”€â”€ weights/                        # Directory for pretrained detection models
```

---

## âš™ï¸ How It Works

### ğŸ”— Modular Pipeline with Chain of Responsibility

The processing stages are implemented as standalone modules:

* Detection (`YOLOv8`)
* Segmentation (`GVF Snake`, `ESAVA`, or `TV/Bilateral`)
* Uniformity scoring (`NUV`)

Each component is dynamically registered and built using YAML configs and Python classes.

### ğŸ” Workflow

1. **Detection** â€“ YOLOv8 locates blastomeres using bounding ellipses.
2. **Refinement** â€“ Active contour or ESAVA segmentation refines the boundary.
3. **Grading** â€“ Calculates **NUV** from areas to assess cell uniformity.

---

## ğŸš€ Getting Started

### ğŸ“¦ Install Dependencies

```bash
# Create virtual environment (Linux/macOS)
python3 -m venv env

# Activate the environment
source env/bin/activate

# --- OR on Windows ---
# python -m venv env
# .\env\Scripts\activate

```

```bash
pip install -r requirements.txt
```

### ğŸ“¥ Download Pretrained Weights

Download the YOLOv8 object detection model weights here:

ğŸ”— **[Download YOLOv8 Weights](https://drive.google.com/drive/folders/1suOTlOYGPH2i7BkMhlE92GpJN3rzUh6y?usp=sharing)**

Then place them inside the `weights/` directory.

> These weights are trained specifically on Day 3 embryo microscope and timelapse data.

---

### â–¶ï¸ Run the Pipeline on a Single Image

```bash
python main.py --pipeline_config config/GVFSnake.yaml --image data/microscope/xcells.jpg
```

---

### ğŸ“‚ Run on Multiple Images with Scripts

Before running:

```bash
chmod +x scripts/microscope_script.sh
chmod +x scripts/timelapse_script.sh
```

Then execute:

```bash
./scripts/microscope_script.sh
./scripts/timelapse_script.sh
```

---

### âš™ï¸ Configurable Pipeline via YAML

Switch between different processing methods via YAML in `config/`:

* `GVFSnake.yaml`: Uses GVF-based snake model
* `Snake.yaml`: Uses basic active contour segmentation
* `ESAVA.yaml`: Uses the reimplemented ESAVA method

---

## ğŸ“Š Main Contributions

* âš™ï¸ A hybrid framework combining YOLOv8 detection with GVF-snake contour refinement
* ğŸ§  Introduction of the **NUV (Normalized Uniformity Value)** for objective blastomere grading
* ğŸ“¦ Modular design using **Chain of Responsibility** + **Builder pattern**
* ğŸ¤– Robust performance on microscope and time-lapse embryo images
* ğŸ” Built-in support for comparing alternative segmentation methods like **ESAVA**

---

## ğŸ§ª Comparative Benchmarking

We reimplemented the **ESAVA method** from the official repository to provide a comparison baseline for segmentation and grading:

ğŸ”— [https://github.com/fsccycy/ESAVA](https://github.com/fsccycy/ESAVA)

This reimplementation was evaluated against our proposed GVF-enhanced contouring pipeline to assess accuracy and grading consistency.

> ğŸ“– **Citation for ESAVA**:

```
Liao Z, Yan C, Wang J, Zhang N, Yang H, Lin C, Zhang H, Wang W, Li W.  
A clinical consensus-compliant deep learning approach to quantitatively evaluate human in vitro fertilization early embryonic development with optical microscope images.  
Artificial Intelligence in Medicine. 2024 Mar;149:102773.  
doi: 10.1016/j.artmed.2024.102773  
PMID: 38462274.
```

## ğŸ™ Acknowledgments

* ğŸ¥ Hung Vuong Hospital, Ho Chi Minh city, Vietnam
* ğŸ§ª HP Fertility Center â€“ Hai Phong International Hospital, Hai Phong city, Vietnam
* ğŸ’» IC-IP Lab, Faculty of Information Technology, Saigon University, Ho Chi Minh city, Vietnam

---

## ğŸ“¬ Contact

ğŸ“§ **[vungocthanhsang@sgu.edu.vn](mailto:vungocthanhsang@sgu.edu.vn)**
ğŸ“§ **[ngduytan288@gmail.com](mailto:ngduytan288@gmail.com)**

---
